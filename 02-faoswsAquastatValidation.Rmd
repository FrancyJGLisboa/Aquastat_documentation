# **The faoswsAquastatValidation module** {#AquastatValidation}

## **Aims**

The faoswsAquastatValidation emerges as a demand for a quality assurance and quality checking tool (QA/QC) that screens AQUASTAT data sets to identify potential issues in the data. The idea is to identify and output a data set containing the information on **what** (elements), **where** (geographic areas), and **when** (year) the domain-knowledge in form of validation rules (logical tests) was violated. 


### **Use validation rules**

The validation modules uses the AQUASTAT domain-knowledge converted into validation rules to identify errors in the data. The validation rules are logical test pre-defined by the technical unit and stored by the ESS-SWS team as a SWS data table called **validation_rule_clone** see \@ (tab:tab14).

- The columns **lhs** and **rhs** represent the left and right side of the validation rule expression. 
- The **operator** the relationship between lhs and rhs that should be tested. 
- The **priority** is a binary variable with 1 (MUST CHECK) and 0 (SHOULD CHECK).


```{r tab15, echo=FALSE, message=FALSE}
require(dplyr)
require(data.table)
d = data.table::fread("tables/validation_rules_clone.csv")
knitr::kable(x = d,
             caption = paste("Validation rule data table in SWS"),
             booktabs = TRUE)
```


### **Focus on high priority rules**

- It was agreed between the technical unit and the ESS - SWS team that the module should focus on the MUST CHECK rules.


### **Output as an email attachment**

- It was agreed that the output of the faoswsAquastatValidation module should send an email with the results to be analyzed by the technical unit

### **Generalization**

- The module is a generic, meaning that it can check and identify potential error of different SWS - AQUASTAT data sets.


## **Workflow**

1. **Input dataset**

2. **Apply validation rules**

3. **Output to the user**



### The input dataset

As requested, the module is designed to be generic and execute on whatever SWS - AQUASTAT data set with at least the following dimensions:

- **geographicAreaM49**
- **aquastatElement**
- **timePointYears**
- **flagObservationStatus** or **flagAquastat**

Currently, the two data sets which the module can be executed on are either the AQUASTAT data set migrated by CIO - SWS (**aquastat_enr**) and the data set resulting from the faoswsAquastatBaseline module (**aquastat_baseline**).


```{r fig15, echo=FALSE, fig.cap='faoswsAquastatValidation module workflow: Input datasets', message=FALSE, warning=FALSE}
require(DiagrammeR)
DiagrammeR::grViz("digraph {
                  
                  graph [layout = dot, rankdir = TB]
                  
                  # define the global styles of the nodes. We can override these in box if we wish
                  node [shape = rectangle, style = filled, fillcolor = Linen]
                  
                  # Inputs
                  enrico [label = 'aquastat_enr \n AQUASTAT data migrated into SWS ', shape = folder, fillcolor = Beige]
                  baseline [label = 'aquastat_baseline \n faoswsAquastatBaseline module output', shape = folder, fillcolor = Beige]                          
                  module [label = 'faoswsAquastatValidation module', shape = folder, fillcolor = LightBlue]
                  
                 
                
                  # Flow
                  # edge definitions with the node IDs
                  {enrico, baseline} -> module   
                  }")
```


### Apply validation rules 

The inputs are then processed by the faoswsAquastatValidation module.
```{r fig16,  echo=FALSE, fig.cap='faoswsAquastatValidation module workflow: Processing', message=FALSE, warning=FALSE}
require(DiagrammeR)
DiagrammeR::grViz("digraph {
                  
                  graph [layout = dot, rankdir = TB]
                  
                  # define the global styles of the nodes. We can override these in box if we wish
                  node [shape = rectangle, style = filled, fillcolor = Linen]
                  
                  # Inputs
                  inputs [label = 'Input \n aquastat_enr/aquastat_baseline', shape = folder, fillcolor = Beige]
                                        
                  module [label = 'faoswsAquastatValidation module \n 1. Call validation_rules_clone data table; \n 2. Confront validation rules against the rows of the input dataset; \n 3. Select the rows of the input where the rules failed; \n 4. Add dimension descriptions to these rows; \n 5. Send the output data to the user corporate email.', shape = folder, fillcolor = LightBlue]
                  
                  # Flow
                  # edge definitions with the node IDs
                  {inputs} -> module   
                  }")
```

### Output to the user 

After processing, and correctly identifying the rows where one or more validation rules were violated,, the module sends the output as **.csv file** to the user email (FAO corporate account). The output .csv file attached in the email is named **validation_<name of the dataset input in SWS>.csv** and has the following columns:

- **geographic_area_description**. The name of the country indicating *where* the validation rule (expression) did not pass the logical test;

- **timePointYears**. The year indicating *when* the validation rule (expression) did not pass the logical test;

- **aquastatElement**. The aquastatElement code;

- **aquastatElement description**. The aquastatElement name(s) in the failing validation rule (expression);

- **Value**. The values of aquastatElement(s) in the geographic area and year that may be potentially erroneous;

- **flagObservationStatus** (if input has flagObservationStatus) or **flagAquastat** (if input is the aquastat_enr data set). The flag of the potentially erroneous values;

- **flagMethod** (if input has flagMethod). The flag pointing the method used to obtain the potentially erroneous values;

- **expression**. The validation rule that was violated and detected by the module.



```{r tab16, echo=FALSE,out.width="100%", message=FALSE}
require(dplyr)
require(data.table)
d = data.table::fread("tables/outputvalidation.csv")
d <- head(d[, .(aquastatElement_description, timePointYears, Value, expression)], 20)
setnames(d, 'timePointYears', 'Year')
knitr::kable(x = d,
             caption = paste("Adapted example of faoswsAquastatValidation output sent by the module to the user (Afghanistan)."),
             booktabs = TRUE) 
```


## **Running the module in the SWS**

1. Log into the SWS;

2. Click on the **New Query** button;

3. Choose **Aquastat domain**;

4. Choose either **aquastat_enr** or Aquastat Baseline as the data set (remember they are the inputs!);

5. Select all countries, all elements, and all years;

6. Click on **Run** besides the save button to query the data;

```{r  fig17, echo=FALSE, out.width="100%", fig.cap=' Running the module in SWS: steps 1 to 6'}
knitr::include_graphics("images/query.JPG")
```  

7. Click on the **Run plugin** button;

8. Select the faoswsAquastatValidation module and click on the **Run plugin** button;

```{r  fig18, echo=FALSE, out.width="100%", fig.cap=' Running the module in SWS: steps 7 to 8'}
knitr::include_graphics("images/validationselectplugin.PNG")
```  

9. Wait for the output in your FAO email inbox; 
```{r  fig19, echo=FALSE, out.width="100%", fig.cap=' Running the module in SWS: step 9'}
knitr::include_graphics("images/validationwaitemail.PNG")
```  

10. Check your inbox.
  - The send is **'sws@fao.org'**.
  - The subject is **'The AquastatValidation is finished'**.
  - The .csv file name is **validation_nameofthedataset.csv**.
  
```{r  fig20, echo=FALSE, out.width="100%", fig.cap=' Running the module in SWS: step 10'}
knitr::include_graphics("images/validationfaoemail.PNG")
```  
  


## **Did the module**...

### execute what it was designed for?

The faoswsAquastatValidation module shows that it is possible to use the domain-knowledge translated into validation rules, and stored as SWS data table, to identify and locate potential errors in AQUASTAT - SWS framework data sets. By returning the areas, years, elements, values, flags, and expressions with potentially erroneous values, the module gives ammunition to the user to reduce the scope of the Quality Assurance and Quality Control process. As a consequence, the tool makes easier to identify the nature of the errors (e.g. from data source, from the module processing, from data revision, etc) and implement data correction based on the user domain - knowledge. 

It is recognized though that the level of human-intervention on the module's result is proportional to the number of rows in the data set identified as violated. The more processed the input data set is, the higher is the probability of more rows with violation. Even so, the burden reduction with the automatic detection of faulty rules is a advance that will help the technical division to improve its data flow.


